{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance Scores Workflow\n",
    "\n",
    "This notebook computes gradient-based importance scores for the following TF prediction tasks:\n",
    "- CTCFL\n",
    "- CEBPB\n",
    "- E2F6\n",
    "- Egr-1\n",
    "- ELF1\n",
    "\n",
    "The scores are saved as npy files and are stored in `/out/importance scores/DeepSea/`. The workflow is general and can be used for all prediction tasks in deepSEA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Environment(conda_kipoi-shared__env__kipoi-py3-keras2)\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import torch\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import kipoi\n",
    "import kipoi_interpret\n",
    "from kipoi_veff.utils.plot import seqlogo_heatmap\n",
    "# Gradient-based methods\n",
    "from kipoi_interpret.importance_scores.gradient import Gradient, GradientXInput\n",
    "# Reference-based method\n",
    "from kipoi_interpret.importance_scores.referencebased import DeepLift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "### check if cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set the path\n",
    "data_dir = '../../data/deepsea_train/'\n",
    "result_dir = '../../out/importance scores/DeepSea/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import DeepSEA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/ubuntu/.kipoi/models/DeepSEA/predict/downloaded/model_files/weights/89e640bf6bdbe1ff165f484d9796efc7\n"
     ]
    }
   ],
   "source": [
    "deep_sea = kipoi.get_model(\"DeepSEA/predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ReCodeAlphabet()\n",
       "  (1): ConcatenateRC()\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(4, 320, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (1): Threshold(threshold=0, value=1e-06)\n",
       "    (2): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Conv2d(320, 480, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (5): Threshold(threshold=0, value=1e-06)\n",
       "    (6): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Conv2d(480, 960, kernel_size=(1, 8), stride=(1, 1))\n",
       "    (9): Threshold(threshold=0, value=1e-06)\n",
       "    (10): Dropout(p=0.5, inplace=False)\n",
       "    (11): Lambda()\n",
       "    (12): Sequential(\n",
       "      (0): Lambda()\n",
       "      (1): Linear(in_features=50880, out_features=925, bias=True)\n",
       "    )\n",
       "    (13): Threshold(threshold=0, value=1e-06)\n",
       "    (14): Sequential(\n",
       "      (0): Lambda()\n",
       "      (1): Linear(in_features=925, out_features=919, bias=True)\n",
       "    )\n",
       "    (15): Sigmoid()\n",
       "  )\n",
       "  (3): AverageRC()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print model architecture\n",
    "deep_sea.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sample datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data of size 10,000 and with corrected ordering \n",
    "with open(data_dir + 'X_test_sample.npy', 'rb') as f:\n",
    "    X_test_sample = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4, 1, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute importance scores for CEBPB, E2F6, Egr-1 and ELF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {'CEBPB':337, 'E2F6':340, 'Egr-1':341, 'ELF1':342}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in tasks.items():\n",
    "\n",
    "    print(key, value)\n",
    "    all_grxinp_scores = np.empty((10000, 1000, 4))\n",
    "    all_gr_scores = np.empty((10000, 1000, 4))\n",
    "\n",
    "    grxinp = GradientXInput(deep_sea, layer = '2.14.1', filter_idx = value) # value specifies TF index\n",
    "    gr = Gradient(deep_sea, layer = '2.14.1', filter_idx = value) \n",
    "\n",
    "    batch_size = 1000\n",
    "    for i in range(10):\n",
    "        tic = time.time()\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        grxinp_scores = grxinp.score(X_test_sample[start:end]) \n",
    "        grxinp_scores = grxinp_scores.squeeze().transpose((0,2,1))\n",
    "        all_grxinp_scores[start:end, :, :] = grxinp_scores\n",
    "\n",
    "        gr_scores = gr.score(X_test_sample[start:end])\n",
    "        gr_scores = gr_scores.squeeze().transpose((0,2,1))\n",
    "        row_means = np.mean(gr_scores, axis=1, keepdims=True) # mean normalize\n",
    "        gr_scores = gr_scores - row_means\n",
    "        all_gr_scores[start:end, :, :] = gr_scores\n",
    "\n",
    "        toc = time.time()\n",
    "        print(str(i) + ' iters completed', round(toc - tic), 'sec elapsed')\n",
    "\n",
    "    np.save(result_dir + key + '_scores.npy', all_grxinp_scores)\n",
    "    np.save(result_dir + key + '_hyp_scores.npy', all_gr_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute importance scores for CTCFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_grxinp_scores = np.empty((10000, 1000, 4))\n",
    "all_gr_scores = np.empty((10000, 1000, 4))\n",
    "\n",
    "grxinp = GradientXInput(deep_sea, layer = '2.14.1', filter_idx = 339) # K562-CTCFL\n",
    "gr = Gradient(deep_sea, layer = '2.14.1', filter_idx = 339) # K562-CTCFL\n",
    "\n",
    "batch_size = 1000\n",
    "for i in range(10):\n",
    "    tic = time.time()\n",
    "    start = i * batch_size\n",
    "    end = start + batch_size\n",
    "    \n",
    "    grxinp_scores = grxinp.score(X_test_sample[start:end]) #n 4 1 1000\n",
    "    grxinp_scores = grxinp_scores.squeeze().transpose((0,2,1))\n",
    "    all_grxinp_scores[start:end, :, :] = grxinp_scores\n",
    "    \n",
    "    gr_scores = gr.score(X_test_sample[start:end])\n",
    "    gr_scores = gr_scores.squeeze().transpose((0,2,1))\n",
    "    row_means = np.mean(gr_scores, axis=1, keepdims=True)\n",
    "    gr_scores = gr_scores - row_means\n",
    "    all_gr_scores[start:end, :, :] = gr_scores\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(str(i) + ' iters completed', round(toc - tic), 'sec elapsed')\n",
    "\n",
    "np.save(result_dir + 'CTCFL_scores.npy', all_grxinp_scores)\n",
    "np.save(result_dir + 'CTCFL_hyp_scores.npy', all_gr_scores)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_kipoi-shared__envs__kipoi-py3-keras2)",
   "language": "python",
   "name": "conda_kipoi-shared__envs__kipoi-py3-keras2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
